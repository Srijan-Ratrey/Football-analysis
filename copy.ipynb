{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# üèÜ Football Performance Analysis System\n",
        "\n",
        "## Advanced AI-Powered Sports Analytics with YOLOv11\n",
        "\n",
        "### üéØ System Overview\n",
        "- **Pose Detection**: MediaPipe for human pose estimation\n",
        "- **Ball Tracking**: **YOLOv11** (Latest & Fastest) for object detection\n",
        "- **Performance Analysis**: Ball control, shooting mechanics, movement patterns\n",
        "- **3D Visualization**: Real-time pose and trajectory analysis\n",
        "- **Coaching Insights**: Automated feedback generation\n",
        "\n",
        "### üöÄ Key Features\n",
        "- Real-time video processing with optimization\n",
        "- Multi-frame pose and ball tracking\n",
        "- Performance metrics and scoring\n",
        "- Interactive dashboard generation\n",
        "- Corrective feedback for improvement\n",
        "\n",
        "### ‚ö° Performance Optimizations\n",
        "- **YOLOv11** for faster ball detection\n",
        "- Frame resizing and skipping\n",
        "- Progress tracking and timeouts\n",
        "- Enhanced detection system\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üì¶ IMPORTS AND SETUP (Updated with YOLOv11)\n",
        "print(\"üîß Loading libraries...\")\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import mediapipe as mp\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import json\n",
        "from pathlib import Path\n",
        "import time\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "from dataclasses import dataclass\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# YOLOv11 (Latest version for better performance)\n",
        "from ultralytics import YOLO\n",
        "\n",
        "print(\"‚úÖ Basic libraries loaded\")\n",
        "\n",
        "# Initialize MediaPipe\n",
        "mp_pose = mp.solutions.pose\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "\n",
        "print(\"‚úÖ MediaPipe initialized\")\n",
        "\n",
        "# Initialize YOLOv11 (Updated from YOLOv8)\n",
        "print(\"üîÑ Loading YOLOv11 model...\")\n",
        "try:\n",
        "    # YOLOv11 nano model for speed (will download automatically if not present)\n",
        "    ball_model = YOLO('yolo11n.pt')  # Changed from yolov8n.pt to yolo11n.pt\n",
        "    print(\"‚úÖ YOLOv11 model loaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è YOLOv11 loading error: {e}\")\n",
        "    print(\"üîÑ Downloading YOLOv11 model...\")\n",
        "    ball_model = YOLO('yolo11n.pt')\n",
        "    print(\"‚úÖ YOLOv11 model downloaded and loaded!\")\n",
        "\n",
        "# Project paths\n",
        "VIDEO_DIR = Path(\"video\")\n",
        "OUTPUT_DIR = Path(\"analysis_results\")\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "print(\"‚úÖ Project directories configured\")\n",
        "print(\"üöÄ All libraries loaded - YOLOv11 ready for ball detection!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ü§∏‚Äç‚ôÇÔ∏è POSE DETECTION CLASS\n",
        "class PoseDetector:\n",
        "    \"\"\"\n",
        "    Advanced pose detection using MediaPipe\n",
        "    Detects and analyzes human body pose in video frames\n",
        "    \"\"\"\n",
        "    def __init__(self, confidence=0.7):\n",
        "        self.pose = mp_pose.Pose(\n",
        "            static_image_mode=False,\n",
        "            model_complexity=1,\n",
        "            enable_segmentation=False,\n",
        "            min_detection_confidence=confidence,\n",
        "            min_tracking_confidence=confidence\n",
        "        )\n",
        "        \n",
        "    def detect_pose(self, frame):\n",
        "        \"\"\"Detect pose landmarks in frame\"\"\"\n",
        "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        results = self.pose.process(frame_rgb)\n",
        "        \n",
        "        if results.pose_landmarks:\n",
        "            return results.pose_landmarks.landmark, results\n",
        "        return None, results\n",
        "    \n",
        "    def get_key_points(self, landmarks):\n",
        "        \"\"\"Extract key body points for analysis\"\"\"\n",
        "        if landmarks is None:\n",
        "            return {}\n",
        "        \n",
        "        # Key points for football analysis\n",
        "        key_points = {\n",
        "            'nose': (landmarks[0].x, landmarks[0].y),\n",
        "            'left_shoulder': (landmarks[11].x, landmarks[11].y),\n",
        "            'right_shoulder': (landmarks[12].x, landmarks[12].y),\n",
        "            'left_elbow': (landmarks[13].x, landmarks[13].y),\n",
        "            'right_elbow': (landmarks[14].x, landmarks[14].y),\n",
        "            'left_wrist': (landmarks[15].x, landmarks[15].y),\n",
        "            'right_wrist': (landmarks[16].x, landmarks[16].y),\n",
        "            'left_hip': (landmarks[23].x, landmarks[23].y),\n",
        "            'right_hip': (landmarks[24].x, landmarks[24].y),\n",
        "            'left_knee': (landmarks[25].x, landmarks[25].y),\n",
        "            'right_knee': (landmarks[26].x, landmarks[26].y),\n",
        "            'left_ankle': (landmarks[27].x, landmarks[27].y),\n",
        "            'right_ankle': (landmarks[28].x, landmarks[28].y),\n",
        "            'left_foot': (landmarks[31].x, landmarks[31].y),\n",
        "            'right_foot': (landmarks[32].x, landmarks[32].y)\n",
        "        }\n",
        "        return key_points\n",
        "\n",
        "# ‚öΩ BALL TRACKER CLASS (Updated with YOLOv11)\n",
        "class BallTracker:\n",
        "    \"\"\"\n",
        "    Advanced ball detection using YOLOv11 (Latest version)\n",
        "    Faster and more accurate than YOLOv8\n",
        "    \"\"\"\n",
        "    def __init__(self, confidence=0.5):\n",
        "        self.model = ball_model  # YOLOv11 model initialized earlier\n",
        "        self.confidence = confidence\n",
        "        self.ball_class_id = 32  # 'sports ball' class in COCO dataset\n",
        "        \n",
        "    def detect_ball(self, frame):\n",
        "        \"\"\"Detect football/soccer ball in frame using YOLOv11\"\"\"\n",
        "        # Run YOLOv11 inference (optimized for speed)\n",
        "        results = self.model(frame, conf=self.confidence, classes=[self.ball_class_id], verbose=False)\n",
        "        \n",
        "        detections = []\n",
        "        for result in results:\n",
        "            boxes = result.boxes\n",
        "            if boxes is not None:\n",
        "                for box in boxes:\n",
        "                    # Extract bounding box coordinates\n",
        "                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
        "                    confidence = float(box.conf[0].cpu().numpy())\n",
        "                    \n",
        "                    # Calculate center and radius\n",
        "                    center_x = int((x1 + x2) / 2)\n",
        "                    center_y = int((y1 + y2) / 2)\n",
        "                    radius = int(max(x2 - x1, y2 - y1) / 2)\n",
        "                    \n",
        "                    detection = {\n",
        "                        'center': (center_x, center_y),\n",
        "                        'radius': radius,\n",
        "                        'bbox': (int(x1), int(y1), int(x2), int(y2)),\n",
        "                        'confidence': confidence\n",
        "                    }\n",
        "                    detections.append(detection)\n",
        "        \n",
        "        return detections\n",
        "\n",
        "print(\"‚úÖ PoseDetector created\")\n",
        "print(\"‚úÖ BallTracker created with YOLOv11\")\n",
        "\n",
        "# Initialize detectors\n",
        "pose_detector = PoseDetector()\n",
        "ball_tracker = BallTracker()\n",
        "\n",
        "print(\"üöÄ Detection components ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üé¨ VIDEO PROCESSOR CLASS (Fixed OpenCV constants)\n",
        "class VideoProcessor:\n",
        "    \"\"\"\n",
        "    Main video processing pipeline for football analysis\n",
        "    FIXED VERSION with correct OpenCV constants\n",
        "    \"\"\"\n",
        "    def __init__(self, video_path):\n",
        "        self.video_path = video_path\n",
        "        self.cap = cv2.VideoCapture(str(video_path))\n",
        "        self.fps = self.cap.get(cv2.CAP_PROP_FPS)\n",
        "        self.frame_count = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        self.width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        self.height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        self.pose_data, self.ball_data = [], []\n",
        "\n",
        "        print(f\"üìπ Video: {video_path.name} | {self.width}x{self.height} | {self.fps:.1f}fps | {self.frame_count/self.fps:.1f}s\")\n",
        "\n",
        "    def visualize_detection(self, frame_number=50):\n",
        "        \"\"\"Create visualization of pose and ball detection\"\"\"\n",
        "        # FIXED: Use CAP_PROP_POS_FRAMES (with S) instead of CAP_PROP_POS_FRAME\n",
        "        self.cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
        "        ret, frame = self.cap.read()\n",
        "        \n",
        "        if not ret:\n",
        "            print(\"‚ùå Could not read frame for visualization\")\n",
        "            return\n",
        "            \n",
        "        # Detect pose and ball\n",
        "        landmarks, pose_results = pose_detector.detect_pose(frame)\n",
        "        ball_detections = ball_tracker.detect_ball(frame)\n",
        "        \n",
        "        # Draw pose\n",
        "        if pose_results.pose_landmarks:\n",
        "            mp_drawing.draw_landmarks(\n",
        "                frame, pose_results.pose_landmarks,\n",
        "                mp_pose.POSE_CONNECTIONS,\n",
        "                mp_drawing_styles.get_default_pose_landmarks_style()\n",
        "            )\n",
        "        \n",
        "        # Draw ball detections\n",
        "        for ball in ball_detections:\n",
        "            center = ball['center']\n",
        "            radius = ball['radius']\n",
        "            confidence = ball['confidence']\n",
        "            \n",
        "            cv2.circle(frame, center, radius, (0, 255, 0), 2)\n",
        "            cv2.putText(frame, f'Ball: {confidence:.2f}', \n",
        "                       (center[0]-50, center[1]-radius-10),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "        \n",
        "        # Save visualization\n",
        "        viz_path = OUTPUT_DIR / f\"detection_sample_{self.video_path.stem}.png\"\n",
        "        cv2.imwrite(str(viz_path), frame)\n",
        "        print(f\"üíæ Visualization saved: {viz_path}\")\n",
        "\n",
        "# ‚öΩ BALL CONTROL ANALYZER CLASS\n",
        "class BallControlAnalyzer:\n",
        "    \"\"\"\n",
        "    Analyzes ball control patterns and player performance\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.touch_threshold = 150  # pixels distance for ball-foot contact\n",
        "        \n",
        "    def detect_ball_touches(self, pose_data, ball_data):\n",
        "        \"\"\"Detect when player touches the ball\"\"\"\n",
        "        touches = []\n",
        "        \n",
        "        for pose_frame in pose_data:\n",
        "            frame_idx = pose_frame['frame_idx']\n",
        "            key_points = pose_frame['key_points']\n",
        "            \n",
        "            # Find ball position at this frame\n",
        "            ball_at_frame = [b for b in ball_data if b['frame_idx'] == frame_idx]\n",
        "            \n",
        "            if ball_at_frame and key_points:\n",
        "                ball_pos = ball_at_frame[0]['center']\n",
        "                \n",
        "                # Check distance to feet\n",
        "                for foot_name in ['left_foot', 'right_foot']:\n",
        "                    if foot_name in key_points:\n",
        "                        foot_pos = key_points[foot_name]\n",
        "                        foot_pixel = (\n",
        "                            int(foot_pos[0] * pose_frame['frame_width']),\n",
        "                            int(foot_pos[1] * pose_frame['frame_height'])\n",
        "                        )\n",
        "                        \n",
        "                        distance = np.sqrt((ball_pos[0] - foot_pixel[0])**2 + \n",
        "                                         (ball_pos[1] - foot_pixel[1])**2)\n",
        "                        \n",
        "                        if distance < self.touch_threshold:\n",
        "                            touches.append({\n",
        "                                'timestamp': pose_frame['timestamp'],\n",
        "                                'foot': foot_name,\n",
        "                                'ball_position': ball_pos,\n",
        "                                'foot_position': foot_pixel,\n",
        "                                'distance': distance\n",
        "                            })\n",
        "        return touches\n",
        "    \n",
        "    def analyze_dribbling_pattern(self, ball_trajectory, touches):\n",
        "        \"\"\"Analyze dribbling patterns and control\"\"\"\n",
        "        if len(touches) < 2:\n",
        "            return None\n",
        "            \n",
        "        # Calculate metrics\n",
        "        total_touches = len(touches)\n",
        "        time_span = touches[-1]['timestamp'] - touches[0]['timestamp']\n",
        "        touch_frequency = total_touches / max(time_span, 1)\n",
        "        \n",
        "        # Foot preference\n",
        "        left_touches = sum(1 for t in touches if 'left' in t['foot'])\n",
        "        right_touches = sum(1 for t in touches if 'right' in t['foot'])\n",
        "        \n",
        "        foot_preference = {\n",
        "            'left': left_touches,\n",
        "            'right': right_touches,\n",
        "            'preference': 'left' if left_touches > right_touches else 'right' if right_touches > left_touches else 'balanced'\n",
        "        }\n",
        "        \n",
        "        # Control consistency (based on touch intervals)\n",
        "        touch_intervals = []\n",
        "        for i in range(1, len(touches)):\n",
        "            interval = touches[i]['timestamp'] - touches[i-1]['timestamp']\n",
        "            touch_intervals.append(interval)\n",
        "        \n",
        "        consistency_score = 1.0 / (1.0 + np.std(touch_intervals)) if touch_intervals else 0\n",
        "        \n",
        "        return {\n",
        "            'total_touches': total_touches,\n",
        "            'touch_frequency': touch_frequency,\n",
        "            'foot_preference': foot_preference,\n",
        "            'control_consistency': {\n",
        "                'consistency_score': consistency_score,\n",
        "                'avg_interval': np.mean(touch_intervals) if touch_intervals else 0\n",
        "            }\n",
        "        }\n",
        "    \n",
        "    def generate_feedback(self, analysis):\n",
        "        \"\"\"Generate coaching feedback based on analysis\"\"\"\n",
        "        feedback = []\n",
        "        \n",
        "        if analysis['touch_frequency'] < 1.0:\n",
        "            feedback.append(\"Increase ball contact frequency for better control\")\n",
        "        elif analysis['touch_frequency'] > 3.0:\n",
        "            feedback.append(\"Good ball contact frequency - maintain this rhythm\")\n",
        "            \n",
        "        consistency = analysis['control_consistency']['consistency_score']\n",
        "        if consistency < 0.5:\n",
        "            feedback.append(\"Work on consistent touch timing for better control\")\n",
        "        else:\n",
        "            feedback.append(\"Excellent touch consistency!\")\n",
        "            \n",
        "        foot_pref = analysis['foot_preference']\n",
        "        if foot_pref['preference'] != 'balanced':\n",
        "            feedback.append(f\"Try using both feet more equally (currently {foot_pref['preference']} foot dominant)\")\n",
        "        else:\n",
        "            feedback.append(\"Great balanced use of both feet!\")\n",
        "            \n",
        "        return feedback\n",
        "\n",
        "print(\"‚úÖ VideoProcessor created with OpenCV fix\")\n",
        "print(\"‚úÖ BallControlAnalyzer created\")\n",
        "\n",
        "# Initialize analyzers\n",
        "ball_control_analyzer = BallControlAnalyzer()\n",
        "\n",
        "print(\"üöÄ Core analysis system ready!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üé¨ Full Video Analysis with Real-Time Display\n",
        "\n",
        "### Complete Football Performance Analysis System\n",
        "- **Video playback** with pose and ball detection overlays\n",
        "- **Real-time analysis** displayed below video\n",
        "- **Performance metrics** updated frame by frame\n",
        "- **Comprehensive report** generation\n",
        "- **Coaching insights** and feedback\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üé¨ FULL VIDEO ANALYSIS WITH REAL-TIME DISPLAY\n",
        "print(\"üé¨ Starting Full Football Analysis with Video Display...\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "import time\n",
        "from IPython.display import display, clear_output, HTML\n",
        "import matplotlib.patches as patches\n",
        "from matplotlib.animation import FuncAnimation\n",
        "import cv2\n",
        "\n",
        "# Analysis Configuration\n",
        "MAX_FRAMES = 200          # Process up to 200 frames for demo\n",
        "SKIP_FRAMES = 2          # Process every 2nd frame for speed\n",
        "RESIZE_WIDTH = 640       # Video display resolution\n",
        "ANALYSIS_UPDATE_FREQ = 15 # Update analysis every N frames\n",
        "SAVE_ANNOTATED_VIDEO = True  # Save video with annotations\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "if VIDEO_DIR.exists() and list(VIDEO_DIR.glob(\"*.mp4\")):\n",
        "    # Get video for analysis (Change [0] to [1], [2], etc. to select different videos)\n",
        "    demo_video = list(VIDEO_DIR.glob(\"*.mp4\"))[0]\n",
        "    print(f\"üé¨ Analyzing: {demo_video.name} ({demo_video.stat().st_size // 1024 // 1024}MB)\")\n",
        "    \n",
        "    try:\n",
        "        # Initialize video processor\n",
        "        processor = VideoProcessor(demo_video)\n",
        "        \n",
        "        # Setup video writer for annotated output\n",
        "        if SAVE_ANNOTATED_VIDEO:\n",
        "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "            annotated_video_path = OUTPUT_DIR / f\"annotated_{demo_video.stem}.mp4\"\n",
        "            video_writer = cv2.VideoWriter(\n",
        "                str(annotated_video_path), \n",
        "                fourcc, \n",
        "                processor.fps, \n",
        "                (RESIZE_WIDTH, int(processor.height * RESIZE_WIDTH / processor.width))\n",
        "            )\n",
        "            print(f\"üìπ Will save annotated video to: {annotated_video_path}\")\n",
        "        \n",
        "        # Analysis tracking variables\n",
        "        frame_analyses = []\n",
        "        ball_touches = []\n",
        "        performance_metrics = {\n",
        "            'total_frames': 0,\n",
        "            'frames_with_pose': 0,\n",
        "            'frames_with_ball': 0,\n",
        "            'ball_touches': 0,\n",
        "            'avg_ball_confidence': 0,\n",
        "            'foot_contacts': {'left': 0, 'right': 0}\n",
        "        }\n",
        "        \n",
        "        # Create real-time analysis display\n",
        "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
        "        fig.suptitle(f'Real-Time Football Analysis: {demo_video.name}', fontsize=14)\n",
        "        \n",
        "        # Initialize plot elements\n",
        "        ax1.set_title('Current Frame with Detection')\n",
        "        ax1.axis('off')\n",
        "        ax2.set_title('Ball Trajectory')\n",
        "        ax3.set_title('Touch Frequency Over Time')\n",
        "        ax4.set_title('Performance Metrics')\n",
        "        \n",
        "        ball_trajectory_x, ball_trajectory_y = [], []\n",
        "        touch_times = []\n",
        "        \n",
        "        print(f\"\\nüîÑ Processing video frames...\")\n",
        "        print(\"üìä Real-time analysis will be displayed below\")\n",
        "        \n",
        "        # Process video frame by frame\n",
        "        processor.cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "        frame_idx, processed = 0, 0\n",
        "        last_update_time = time.time()\n",
        "        \n",
        "        while processed < MAX_FRAMES:\n",
        "            # Read frame\n",
        "            ret, frame = processor.cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "                \n",
        "            if frame_idx % SKIP_FRAMES == 0:\n",
        "                # Resize frame for processing and display\n",
        "                h, w = frame.shape[:2]\n",
        "                scale = RESIZE_WIDTH / w\n",
        "                new_h = int(h * scale)\n",
        "                frame_resized = cv2.resize(frame, (RESIZE_WIDTH, new_h))\n",
        "                \n",
        "                # Create annotated frame for display and saving\n",
        "                annotated_frame = frame_resized.copy()\n",
        "                \n",
        "                # Detect pose\n",
        "                landmarks, pose_results = pose_detector.detect_pose(frame_resized)\n",
        "                key_points = pose_detector.get_key_points(landmarks)\n",
        "                \n",
        "                # Detect ball\n",
        "                ball_detections = ball_tracker.detect_ball(frame_resized)\n",
        "                \n",
        "                # Draw pose on annotated frame\n",
        "                if pose_results.pose_landmarks:\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        annotated_frame, pose_results.pose_landmarks,\n",
        "                        mp_pose.POSE_CONNECTIONS,\n",
        "                        mp_drawing_styles.get_default_pose_landmarks_style()\n",
        "                    )\n",
        "                    performance_metrics['frames_with_pose'] += 1\n",
        "                \n",
        "                # Draw ball detections on annotated frame\n",
        "                current_ball_pos = None\n",
        "                if ball_detections:\n",
        "                    performance_metrics['frames_with_ball'] += 1\n",
        "                    ball_confidences = []\n",
        "                    \n",
        "                    for ball in ball_detections:\n",
        "                        center = ball['center']\n",
        "                        radius = ball['radius']\n",
        "                        confidence = ball['confidence']\n",
        "                        ball_confidences.append(confidence)\n",
        "                        \n",
        "                        # Draw ball detection\n",
        "                        cv2.circle(annotated_frame, center, radius, (0, 255, 0), 3)\n",
        "                        cv2.circle(annotated_frame, center, 5, (0, 255, 0), -1)  # Center dot\n",
        "                        cv2.putText(annotated_frame, f'Ball: {confidence:.2f}', \n",
        "                                   (center[0]-40, center[1]-radius-10),\n",
        "                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "                        \n",
        "                        current_ball_pos = center\n",
        "                        ball_trajectory_x.append(center[0])\n",
        "                        ball_trajectory_y.append(center[1])\n",
        "                    \n",
        "                    # Update ball confidence average\n",
        "                    if ball_confidences:\n",
        "                        performance_metrics['avg_ball_confidence'] = np.mean(ball_confidences)\n",
        "                \n",
        "                # Analyze ball touches\n",
        "                if landmarks and ball_detections and key_points:\n",
        "                    frame_data = {\n",
        "                        'frame_idx': frame_idx,\n",
        "                        'timestamp': frame_idx / processor.fps,\n",
        "                        'key_points': key_points,\n",
        "                        'frame_width': RESIZE_WIDTH,\n",
        "                        'frame_height': new_h\n",
        "                    }\n",
        "                    \n",
        "                    # Check for ball touches\n",
        "                    for ball in ball_detections:\n",
        "                        ball_pos = ball['center']\n",
        "                        \n",
        "                        for foot_name in ['left_foot', 'right_foot']:\n",
        "                            if foot_name in key_points:\n",
        "                                foot_pos = key_points[foot_name]\n",
        "                                foot_pixel = (\n",
        "                                    int(foot_pos[0] * RESIZE_WIDTH),\n",
        "                                    int(foot_pos[1] * new_h)\n",
        "                                )\n",
        "                                \n",
        "                                distance = np.sqrt((ball_pos[0] - foot_pixel[0])**2 + \n",
        "                                                 (ball_pos[1] - foot_pixel[1])**2)\n",
        "                                \n",
        "                                if distance < 100:  # Touch threshold\n",
        "                                    performance_metrics['ball_touches'] += 1\n",
        "                                    performance_metrics['foot_contacts'][foot_name.split('_')[0]] += 1\n",
        "                                    touch_times.append(frame_idx / processor.fps)\n",
        "                                    \n",
        "                                    # Draw touch indicator\n",
        "                                    cv2.circle(annotated_frame, foot_pixel, 15, (255, 0, 255), 3)\n",
        "                                    cv2.putText(annotated_frame, 'TOUCH!', \n",
        "                                               (foot_pixel[0]-20, foot_pixel[1]-20),\n",
        "                                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 255), 2)\n",
        "                \n",
        "                # Add frame info overlay\n",
        "                timestamp = frame_idx / processor.fps\n",
        "                info_text = [\n",
        "                    f\"Frame: {frame_idx} | Time: {timestamp:.1f}s\",\n",
        "                    f\"Pose: {'‚úì' if landmarks else '‚úó'} | Ball: {'‚úì' if ball_detections else '‚úó'}\",\n",
        "                    f\"Touches: {performance_metrics['ball_touches']}\"\n",
        "                ]\n",
        "                \n",
        "                for i, text in enumerate(info_text):\n",
        "                    cv2.putText(annotated_frame, text, (10, 25 + i*20),\n",
        "                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
        "                    cv2.putText(annotated_frame, text, (10, 25 + i*20),\n",
        "                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 1)\n",
        "                \n",
        "                # Save annotated frame to video\n",
        "                if SAVE_ANNOTATED_VIDEO and video_writer:\n",
        "                    video_writer.write(annotated_frame)\n",
        "                \n",
        "                # Update performance metrics\n",
        "                performance_metrics['total_frames'] = processed + 1\n",
        "                \n",
        "                # Update real-time display every N frames\n",
        "                if processed % ANALYSIS_UPDATE_FREQ == 0 or processed < 5:\n",
        "                    clear_output(wait=True)\n",
        "                    \n",
        "                    # Current frame display\n",
        "                    ax1.clear()\n",
        "                    ax1.imshow(cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB))\n",
        "                    ax1.set_title(f'Frame {frame_idx} - Time: {timestamp:.1f}s')\n",
        "                    ax1.axis('off')\n",
        "                    \n",
        "                    # Ball trajectory\n",
        "                    ax2.clear()\n",
        "                    if len(ball_trajectory_x) > 1:\n",
        "                        ax2.plot(ball_trajectory_x, ball_trajectory_y, 'ro-', alpha=0.6, markersize=3)\n",
        "                        ax2.set_xlim(0, RESIZE_WIDTH)\n",
        "                        ax2.set_ylim(0, new_h)\n",
        "                        ax2.invert_yaxis()\n",
        "                    ax2.set_title(f'Ball Trajectory ({len(ball_trajectory_x)} points)')\n",
        "                    ax2.grid(True, alpha=0.3)\n",
        "                    \n",
        "                    # Touch frequency\n",
        "                    ax3.clear()\n",
        "                    if touch_times:\n",
        "                        ax3.hist(touch_times, bins=max(1, len(touch_times)//3), alpha=0.7, color='orange')\n",
        "                    ax3.set_title(f'Ball Touches Over Time ({len(touch_times)} total)')\n",
        "                    ax3.set_xlabel('Time (seconds)')\n",
        "                    ax3.set_ylabel('Touch Count')\n",
        "                    \n",
        "                    # Performance metrics\n",
        "                    ax4.clear()\n",
        "                    metrics_data = [\n",
        "                        performance_metrics['frames_with_pose'] / max(1, performance_metrics['total_frames']) * 100,\n",
        "                        performance_metrics['frames_with_ball'] / max(1, performance_metrics['total_frames']) * 100,\n",
        "                        performance_metrics['avg_ball_confidence'] * 100,\n",
        "                        min(performance_metrics['ball_touches'] * 10, 100)  # Scale touches\n",
        "                    ]\n",
        "                    metrics_labels = ['Pose\\nDetection %', 'Ball\\nDetection %', 'Ball\\nConfidence %', 'Touch\\nActivity']\n",
        "                    colors = ['skyblue', 'lightgreen', 'gold', 'coral']\n",
        "                    \n",
        "                    bars = ax4.bar(metrics_labels, metrics_data, color=colors)\n",
        "                    ax4.set_ylim(0, 100)\n",
        "                    ax4.set_title('Real-Time Performance Metrics')\n",
        "                    \n",
        "                    # Add value labels on bars\n",
        "                    for bar, value in zip(bars, metrics_data):\n",
        "                        height = bar.get_height()\n",
        "                        ax4.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
        "                                f'{value:.1f}', ha='center', va='bottom', fontsize=9)\n",
        "                    \n",
        "                    plt.tight_layout()\n",
        "                    plt.show()\n",
        "                    \n",
        "                    # Print progress\n",
        "                    elapsed = time.time() - start_time\n",
        "                    progress = processed / MAX_FRAMES\n",
        "                    eta = (elapsed / progress - elapsed) if progress > 0 else 0\n",
        "                    \n",
        "                    print(f\"üìä Progress: {processed}/{MAX_FRAMES} ({progress*100:.1f}%) | \"\n",
        "                          f\"Elapsed: {elapsed:.0f}s | ETA: {eta:.0f}s\")\n",
        "                    print(f\"‚öΩ Detections: Pose={performance_metrics['frames_with_pose']}, \"\n",
        "                          f\"Ball={performance_metrics['frames_with_ball']}, \"\n",
        "                          f\"Touches={performance_metrics['ball_touches']}\")\n",
        "                \n",
        "                processed += 1\n",
        "            frame_idx += 1\n",
        "        \n",
        "        # Close video writer\n",
        "        if SAVE_ANNOTATED_VIDEO and video_writer:\n",
        "            video_writer.release()\n",
        "            print(f\"\\nüìπ Annotated video saved: {annotated_video_path}\")\n",
        "        \n",
        "        # Final analysis and report generation\n",
        "        total_time = time.time() - start_time\n",
        "        \n",
        "        print(f\"\\nüéâ VIDEO ANALYSIS COMPLETE!\")\n",
        "        print(f\"‚è±Ô∏è  Total processing time: {total_time//60:.0f}min {total_time%60:.1f}s\")\n",
        "        print(f\"üìä Processed {performance_metrics['total_frames']} frames\")\n",
        "        \n",
        "        # Generate comprehensive report\n",
        "        report = {\n",
        "            'video_info': {\n",
        "                'filename': demo_video.name,\n",
        "                'total_frames_processed': performance_metrics['total_frames'],\n",
        "                'processing_time_seconds': total_time,\n",
        "                'fps': processor.fps\n",
        "            },\n",
        "            'detection_performance': {\n",
        "                'pose_detection_rate': performance_metrics['frames_with_pose'] / performance_metrics['total_frames'],\n",
        "                'ball_detection_rate': performance_metrics['frames_with_ball'] / performance_metrics['total_frames'],\n",
        "                'average_ball_confidence': performance_metrics['avg_ball_confidence']\n",
        "            },\n",
        "            'ball_control_analysis': {\n",
        "                'total_ball_touches': performance_metrics['ball_touches'],\n",
        "                'touch_frequency': performance_metrics['ball_touches'] / (performance_metrics['total_frames'] / processor.fps),\n",
        "                'foot_preference': performance_metrics['foot_contacts'],\n",
        "                'ball_trajectory_points': len(ball_trajectory_x)\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        # Save detailed report\n",
        "        report_path = OUTPUT_DIR / f\"analysis_report_{demo_video.stem}.json\"\n",
        "        with open(report_path, 'w') as f:\n",
        "            json.dump(report, f, indent=2)\n",
        "        \n",
        "        print(f\"\\nüìÑ ANALYSIS REPORT:\")\n",
        "        print(f\"   üé¨ Video: {report['video_info']['filename']}\")\n",
        "        print(f\"   üìä Frames processed: {report['video_info']['total_frames_processed']}\")\n",
        "        print(f\"   ü§∏ Pose detection: {report['detection_performance']['pose_detection_rate']*100:.1f}%\")\n",
        "        print(f\"   ‚öΩ Ball detection: {report['detection_performance']['ball_detection_rate']*100:.1f}%\")\n",
        "        print(f\"   üèÉ Ball touches: {report['ball_control_analysis']['total_ball_touches']}\")\n",
        "        print(f\"   ü¶∂ Foot preference: L:{report['ball_control_analysis']['foot_preference']['left']} R:{report['ball_control_analysis']['foot_preference']['right']}\")\n",
        "        \n",
        "        # Generate coaching feedback\n",
        "        feedback = []\n",
        "        \n",
        "        if report['detection_performance']['pose_detection_rate'] > 0.8:\n",
        "            feedback.append(\"‚úÖ Excellent pose visibility throughout the video\")\n",
        "        elif report['detection_performance']['pose_detection_rate'] > 0.5:\n",
        "            feedback.append(\"‚ö†Ô∏è Good pose detection - consider better camera angle for improvement\")\n",
        "        else:\n",
        "            feedback.append(\"‚ùå Poor pose detection - check camera position and lighting\")\n",
        "            \n",
        "        if report['ball_control_analysis']['total_ball_touches'] > 5:\n",
        "            feedback.append(\"‚öΩ Good ball control activity detected\")\n",
        "        else:\n",
        "            feedback.append(\"‚öΩ Limited ball contact detected - focus on ball control drills\")\n",
        "            \n",
        "        left_touches = report['ball_control_analysis']['foot_preference']['left']\n",
        "        right_touches = report['ball_control_analysis']['foot_preference']['right']\n",
        "        if abs(left_touches - right_touches) > 3:\n",
        "            dominant_foot = 'left' if left_touches > right_touches else 'right'\n",
        "            feedback.append(f\"ü¶∂ {dominant_foot.capitalize()} foot dominant - practice with both feet\")\n",
        "        else:\n",
        "            feedback.append(\"ü¶∂ Good balanced use of both feet\")\n",
        "        \n",
        "        print(f\"\\nüí¨ COACHING FEEDBACK:\")\n",
        "        for i, fb in enumerate(feedback, 1):\n",
        "            print(f\"   {i}. {fb}\")\n",
        "        \n",
        "        print(f\"\\nüìÅ FILES GENERATED:\")\n",
        "        if SAVE_ANNOTATED_VIDEO:\n",
        "            print(f\"   üé¨ Annotated video: {annotated_video_path}\")\n",
        "        print(f\"   üìÑ Analysis report: {report_path}\")\n",
        "        print(f\"   üìä Performance charts: Displayed above\")\n",
        "        \n",
        "        print(f\"\\nüèÜ FOOTBALL ANALYSIS SYSTEM COMPLETE!\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error during analysis: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        \n",
        "else:\n",
        "    print(\"‚ùå No video files found in 'video' directory!\")\n",
        "    print(\"üìÅ Please add .mp4 files to analyze\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üèÜ Football Analysis System - Complete & Saved!\n",
        "\n",
        "### ‚úÖ **Current System State:**\n",
        "\n",
        "#### üé¨ **Real-Time Video Analysis:**\n",
        "- **Live video display** with pose and ball detection overlays\n",
        "- **Frame-by-frame processing** with YOLOv11 ball tracking\n",
        "- **Real-time metrics** updated every 15 frames\n",
        "- **Touch detection** with visual indicators\n",
        "\n",
        "#### üìä **Interactive Analysis Dashboard:**\n",
        "- **Current frame** with all detections highlighted\n",
        "- **Ball trajectory** tracking throughout video\n",
        "- **Touch frequency** histogram over time\n",
        "- **Performance metrics** with live percentages\n",
        "\n",
        "#### üìπ **Video Output:**\n",
        "- **Annotated video** saved with all detections\n",
        "- **Touch indicators** and confidence scores\n",
        "- **Frame information** overlay\n",
        "- **Professional video output** for review\n",
        "\n",
        "#### üìÑ **Comprehensive Reports:**\n",
        "- **JSON analysis report** with detailed metrics\n",
        "- **Coaching feedback** based on performance\n",
        "- **Detection statistics** (pose/ball detection rates)\n",
        "- **Ball control analysis** (touches, foot preference)\n",
        "\n",
        "### üöÄ **How to Use:**\n",
        "\n",
        "1. **Run Cell 1**: Load YOLOv11 and libraries\n",
        "2. **Run Cell 2**: Initialize detection components  \n",
        "3. **Run Cell 3**: Setup video processor and analyzers\n",
        "4. **Run Cell 5**: **Full video analysis** with real-time display\n",
        "\n",
        "### üìÅ **Generated Files:**\n",
        "- `annotated_{video_name}.mp4` - Video with detections\n",
        "- `analysis_report_{video_name}.json` - Detailed analysis\n",
        "- Real-time charts and visualizations\n",
        "\n",
        "### ‚ö° **Performance Optimized:**\n",
        "- **YOLOv11** for fastest ball detection\n",
        "- **Configurable frame processing** (skip frames, resize)\n",
        "- **Progress tracking** with ETA\n",
        "- **Real-time display updates**\n",
        "\n",
        "### üéØ **To Select Different Videos:**\n",
        "In Cell 5, change `[0]` to `[1]`, `[2]`, etc. in this line:\n",
        "```python\n",
        "demo_video = list(VIDEO_DIR.glob(\"*.mp4\"))[0]  # Change [0] to select different video\n",
        "```\n",
        "\n",
        "### üíæ **System State:**\n",
        "**‚úÖ SUCCESSFULLY SAVED - Your complete football analysis system is now preserved!**\n",
        "\n",
        "This notebook contains:\n",
        "- Complete YOLOv11 integration\n",
        "- All performance optimizations\n",
        "- Real-time video analysis\n",
        "- Professional reporting system\n",
        "- All bug fixes applied\n",
        "\n",
        "**Ready to use whenever you run the cells! üöÄ‚öΩ**\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
